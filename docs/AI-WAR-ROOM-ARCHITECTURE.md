# AI War Room - System Architecture

## ğŸ—ï¸ Component Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                        LiveDashboard.tsx                         â”‚
â”‚  (Main React Component - 1100+ lines)                           â”‚
â”‚                                                                  â”‚
â”‚  State Management:                                               â”‚
â”‚  - Projects (War Rooms)                                         â”‚
â”‚  - Sessions (Conversations)                                      â”‚
â”‚  - Messages (Chat history)                                       â”‚
â”‚  - Documents (Knowledge base)                                    â”‚
â”‚  - Thinking Logs (AI reasoning steps)                          â”‚
â”‚  - Prompt Suggestions (Context-aware)                          â”‚
â”‚  - UI State (sidebar, modals, loading)                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â”‚
                              â”‚ calls
                              â–¼
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚              ragService.ts (Enhanced)                    â”‚
    â”‚                                                          â”‚
    â”‚  Project Management:                                     â”‚
    â”‚  â”œâ”€ createProject()                                      â”‚
    â”‚  â”œâ”€ getProjects()                                        â”‚
    â”‚  â””â”€ deleteProject()                                      â”‚
    â”‚                                                          â”‚
    â”‚  Session Management:                                     â”‚
    â”‚  â”œâ”€ createSession() [project-aware]                     â”‚
    â”‚  â”œâ”€ getSessions() [filtered by project]                 â”‚
    â”‚  â”œâ”€ getMessages()                                        â”‚
    â”‚  â”œâ”€ addMessage()                                         â”‚
    â”‚  â””â”€ deleteSession()                                      â”‚
    â”‚                                                          â”‚
    â”‚  Document & RAG:                                         â”‚
    â”‚  â”œâ”€ ingestTextDocument() [with AI summary/keywords]     â”‚
    â”‚  â”œâ”€ getDocuments() [project-filtered]                   â”‚
    â”‚  â”œâ”€ searchSimilar() [project-filtered vector search]    â”‚
    â”‚  â”œâ”€ deleteDocument()                                     â”‚
    â”‚  â””â”€ chunkText()                                          â”‚
    â”‚                                                          â”‚
    â”‚  AI Intelligence:                                        â”‚
    â”‚  â”œâ”€ saveThinkingLog()                                    â”‚
    â”‚  â”œâ”€ getThinkingLog()                                     â”‚
    â”‚  â”œâ”€ generateSuggestions()                                â”‚
    â”‚  â”œâ”€ getSuggestions()                                     â”‚
    â”‚  â””â”€ markSuggestionUsed()                                 â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                    â”‚                        â”‚
                    â”‚                        â”‚
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚  geminiService.ts   â”‚    â”‚   Supabase DB     â”‚
        â”‚                     â”‚    â”‚                   â”‚
        â”‚  - processWithModel â”‚    â”‚  Tables:          â”‚
        â”‚  - generateEmbeddingâ”‚    â”‚  â”œâ”€ ai_projects   â”‚
        â”‚  - generateSpeech   â”‚    â”‚  â”œâ”€ ai_sessions   â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚  â”œâ”€ ai_messages   â”‚
                                   â”‚  â”œâ”€ knowledge_docsâ”‚
                                   â”‚  â”œâ”€ doc_embeddingsâ”‚
                                   â”‚  â”œâ”€ project_docs  â”‚
                                   â”‚  â”œâ”€ ai_thinking_logsâ”‚
                                   â”‚  â””â”€ ai_prompt_suggestionsâ”‚
                                   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ“Š Data Flow Diagrams

### 1. Document Upload & Processing Flow

```
User Uploads File
      â”‚
      â–¼
[LiveDashboard] handleFileUpload()
      â”‚
      â”œâ”€ Read file as text (FileReader)
      â”‚
      â–¼
[ragService] ingestTextDocument()
      â”‚
      â”œâ”€ 1. Create doc record in DB (status: 'processing')
      â”‚     â””â”€ Link to project (project_docs)
      â”‚
      â”œâ”€ 2. PARALLEL: Generate AI summary & keywords
      â”‚     â”œâ”€ [geminiService] processWithModel() â†’ Summary
      â”‚     â””â”€ [geminiService] processWithModel() â†’ Keywords
      â”‚
      â”œâ”€ 3. Chunk text (1000 chars, 100 overlap)
      â”‚
      â”œâ”€ 4. LOOP: Generate embeddings (max 50 chunks)
      â”‚     â””â”€ [geminiService] generateEmbedding()
      â”‚           â””â”€ REST API: /v1beta/models/text-embedding-004:embedContent
      â”‚
      â”œâ”€ 5. Save embeddings to doc_embeddings table
      â”‚
      â””â”€ 6. Update doc (status: 'completed', ai_summary, ai_keywords)
            â”‚
            â–¼
      Toast: "âœ… file.txt indexed with AI summary!"
```

### 2. AI Chat with RAG Flow

```
User Sends Message
      â”‚
      â–¼
[LiveDashboard] handleSendMessage()
      â”‚
      â”œâ”€ 1. Add user message to DB
      â”‚
      â”œâ”€ 2. IF enableExtendedThinking:
      â”‚     â””â”€ Start logging thinking steps with timestamps
      â”‚
      â”œâ”€ 3. IF documents exist:
      â”‚     â”‚
      â”‚     â””â”€ [ragService] searchSimilar()
      â”‚           â”‚
      â”‚           â”œâ”€ Generate query embedding
      â”‚           â”‚   â””â”€ [geminiService] generateEmbedding()
      â”‚           â”‚
      â”‚           â”œâ”€ Call match_documents() RPC (vector search)
      â”‚           â”‚   â””â”€ Returns top 5 chunks with similarity > 0.5
      â”‚           â”‚
      â”‚           â””â”€ IF projectId: Filter by project_docs
      â”‚
      â”œâ”€ 4. Build context prompt:
      â”‚     â”œâ”€ Agent persona system prompt
      â”‚     â”œâ”€ Document chunks (if found)
      â”‚     â””â”€ User query
      â”‚
      â”œâ”€ 5. [geminiService] processWithModel()
      â”‚     â””â”€ REST API: /v1beta/models/gemini-2.0-flash-exp:generateContent
      â”‚
      â”œâ”€ 6. Add AI message to DB with citations
      â”‚
      â”œâ”€ 7. IF enableExtendedThinking:
      â”‚     â””â”€ [ragService] saveThinkingLog()
      â”‚
      â””â”€ 8. ASYNC: Generate prompt suggestions
            â””â”€ [ragService] generateSuggestions()
```

### 3. Project/War Room Isolation

```
User Selects Project
      â”‚
      â–¼
[LiveDashboard] setSelectedProjectId(id)
      â”‚
      â”œâ”€ useEffect triggers on projectId change
      â”‚
      â”œâ”€ loadSessions()
      â”‚   â””â”€ [ragService] getSessions(userId, projectId)
      â”‚         â””â”€ SQL: WHERE project_id = ?
      â”‚
      â””â”€ loadDocuments()
          â””â”€ [ragService] getDocuments(userId, projectId)
                â”‚
                â”œâ”€ Query project_docs WHERE project_id = ?
                â”‚   â””â”€ Get list of doc_ids
                â”‚
                â””â”€ Query knowledge_docs WHERE id IN (doc_ids)
```

---

## ğŸ—„ï¸ Database Schema Relationships

```
users (public.users)
  â”‚
  â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ ai_projects (1:many)
  â”‚                 â”‚
  â”‚                 â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ ai_sessions (1:many)
  â”‚                 â”‚                 â”‚
  â”‚                 â”‚                 â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ ai_messages (1:many)
  â”‚                 â”‚                 â”‚                 â”‚
  â”‚                 â”‚                 â”‚                 â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ ai_thinking_logs (1:1)
  â”‚                 â”‚                 â”‚
  â”‚                 â”‚                 â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ ai_prompt_suggestions (1:many)
  â”‚                 â”‚
  â”‚                 â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ project_docs (many:many)
  â”‚                                   â”‚
  â”‚                                   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ knowledge_docs
  â”‚
  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ knowledge_docs (1:many)
                    â”‚
                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ doc_embeddings (1:many)
                          â”‚
                          â””â”€ embedding: VECTOR(768)
                          â””â”€ content: TEXT (chunk)
```

### Key Relationships:
- **Users â†’ Projects**: One user can have many war rooms
- **Projects â†’ Sessions**: Each session belongs to one project (nullable)
- **Projects â†’ Documents**: Many-to-many via `project_docs`
- **Documents â†’ Embeddings**: One doc split into many chunks
- **Messages â†’ Thinking Logs**: Each AI message can have one thinking log
- **Sessions â†’ Suggestions**: Auto-generated prompts for each session

---

## ğŸ” Security Model (RLS Policies)

```
ai_projects:
  â”œâ”€ Users can CRUD own projects
  â””â”€ WHERE user_id = auth.uid()

ai_sessions:
  â”œâ”€ Users can CRUD own sessions
  â””â”€ WHERE user_id = auth.uid()

ai_messages:
  â”œâ”€ Users can SELECT messages in own sessions
  â”œâ”€ Users can INSERT own messages
  â””â”€ AI can INSERT messages (user_id IS NULL)

knowledge_docs:
  â”œâ”€ Users can CRUD own docs
  â””â”€ Team can SELECT all docs (team knowledge base)

doc_embeddings:
  â”œâ”€ Users can INSERT any embeddings (team contribution)
  â””â”€ Users can SELECT all embeddings (shared knowledge)

project_docs:
  â””â”€ Users can CRUD links for own projects

ai_thinking_logs:
  â””â”€ Users can SELECT logs for messages in own sessions

ai_prompt_suggestions:
  â””â”€ Users can CRUD suggestions for own sessions
```

---

## ğŸš€ API Integrations

### Gemini API Endpoints Used:

1. **Text Generation**
   - Endpoint: `POST /v1beta/models/gemini-2.0-flash-exp:generateContent`
   - Used for: AI responses, summaries, keywords, suggestions
   - Rate limit: ~60 requests/minute

2. **Text Embeddings**
   - Endpoint: `POST /v1beta/models/text-embedding-004:embedContent`
   - Used for: Document chunking, query embeddings
   - Dimensions: 768
   - Rate limit: Throttled to 200ms between calls

3. **Speech Synthesis**
   - Endpoint: Custom (via generateSpeech)
   - Used for: Audio overviews
   - Format: MP3

### Supabase RPC Functions:

1. **match_documents()**
   - Performs cosine similarity search
   - Returns top N chunks above threshold
   - Joins with knowledge_docs for metadata
   - Filterable by user_id

---

## ğŸ¨ UI Component Hierarchy

```
LiveDashboard
â”‚
â”œâ”€ Sidebar (collapsible)
â”‚   â”œâ”€ Header ("AI War Room")
â”‚   â”œâ”€ War Rooms Selector
â”‚   â”‚   â”œâ”€ Create Project Form
â”‚   â”‚   â””â”€ Project List (with delete)
â”‚   â”œâ”€ Sessions List
â”‚   â”‚   â”œâ”€ Create Session Form
â”‚   â”‚   â””â”€ Session Cards (with delete)
â”‚   â””â”€ Knowledge Base Button (with count badge)
â”‚
â”œâ”€ Main Content Area
â”‚   â”œâ”€ Header Bar
â”‚   â”‚   â”œâ”€ Sidebar Toggle
â”‚   â”‚   â”œâ”€ Project Badge (if selected)
â”‚   â”‚   â”œâ”€ Session Title
â”‚   â”‚   â”œâ”€ Deep Thinking Toggle
â”‚   â”‚   â”œâ”€ Agent Selector Dropdown
â”‚   â”‚   â”œâ”€ Upload Button
â”‚   â”‚   â””â”€ Audio Button
â”‚   â”‚
â”‚   â”œâ”€ Messages Area
â”‚   â”‚   â”œâ”€ Empty State
â”‚   â”‚   â”‚   â”œâ”€ Quick Start Cards (4 options)
â”‚   â”‚   â”‚   â””â”€ Knowledge Base Indicator
â”‚   â”‚   â”‚
â”‚   â”‚   â””â”€ Message List
â”‚   â”‚       â””â”€ Message Bubble
â”‚   â”‚           â”œâ”€ Content
â”‚   â”‚           â”œâ”€ Citations (if AI message)
â”‚   â”‚           â”œâ”€ Thinking Log (collapsible)
â”‚   â”‚           â””â”€ Timestamp
â”‚   â”‚
â”‚   â”œâ”€ Prompt Suggestions Bar (dismissible)
â”‚   â”‚   â””â”€ Suggestion Pills (clickable)
â”‚   â”‚
â”‚   â””â”€ Input Area
â”‚       â”œâ”€ Context Indicators (active docs)
â”‚       â”œâ”€ Text Input
â”‚       â””â”€ Send Button
â”‚
â””â”€ Modals
    â””â”€ Knowledge Library Modal (full-screen overlay)
        â”œâ”€ Header (with count)
        â”œâ”€ Document Grid
        â”‚   â””â”€ Document Card
        â”‚       â”œâ”€ Title & Metadata
        â”‚       â”œâ”€ AI Summary Box
        â”‚       â”œâ”€ Keyword Tags
        â”‚       â””â”€ Delete Button
        â””â”€ Close Button
```

---

## ğŸ§  AI Agent System

### Agent Personas:

```typescript
const agentPrompts = {
  general: 'Helpful AI assistant. Clear and concise.',
  skeptic: 'Critical thinker. Questions assumptions. Constructive.',
  scribe: 'Meticulous note-taker. Bullet points and structure.',
  'deep-diver': 'Analytical researcher. Comprehensive with nuance.'
};
```

### Thinking Process (when enabled):

```
Step 1: Analyze Query
  â””â”€ Parse user intent
  â””â”€ Identify key entities

Step 2: Search Knowledge Base
  â””â”€ Generate query embedding
  â””â”€ Vector similarity search

Step 3: Select Context
  â””â”€ Rank document chunks
  â””â”€ Build citation list

Step 4: Formulate Response
  â””â”€ Apply agent persona
  â””â”€ Incorporate context

Step 5: Generate Output
  â””â”€ Stream response
  â””â”€ Track token count
```

---

## ğŸ“ˆ Performance Considerations

### Bottlenecks:
1. **Document Upload**: Embedding generation (50 chunks Ã— 200ms = 10s)
2. **RAG Search**: Vector similarity (optimized via pgvector index)
3. **AI Response**: Gemini API latency (~2-3s)
4. **Thinking Logs**: Adds ~500ms overhead

### Optimizations:
- âœ… Parallel summary + keyword generation
- âœ… Chunk limit (50 max)
- âœ… Rate limiting (200ms between embeddings)
- âœ… Lazy loading thinking logs
- âœ… Background suggestion generation
- âœ… Indexed foreign keys
- âœ… RLS policies for security without N+1 queries

### Scaling Considerations:
- **1-100 docs**: Current implementation works great
- **100-1000 docs**: May need pagination, search optimization
- **1000+ docs**: Consider document clustering, hierarchical RAG

---

## ğŸ”„ State Management Pattern

Uses **React Hooks** with clear separation:

```typescript
// Core Data
const [projects, setProjects] = useState<AIProject[]>([]);
const [sessions, setSessions] = useState<AISession[]>([]);
const [messages, setMessages] = useState<AIMessage[]>([]);
const [documents, setDocuments] = useState<KnowledgeDoc[]>([]);

// UI State
const [isSidebarOpen, setIsSidebarOpen] = useState(true);
const [showDocLibrary, setShowDocLibrary] = useState(false);
const [isLoading, setIsLoading] = useState(false);

// Selection State
const [selectedProjectId, setSelectedProjectId] = useState<string | null>(null);
const [selectedSessionId, setSelectedSessionId] = useState<string | null>(null);

// AI Features
const [thinkingLogs, setThinkingLogs] = useState<Map<string, ThinkingStep[]>>(new Map());
const [suggestions, setSuggestions] = useState<PromptSuggestion[]>([]);
const [activeAgent, setActiveAgent] = useState<AgentType>('general');
const [enableExtendedThinking, setEnableExtendedThinking] = useState(false);

// Refs for side effects
const messagesEndRef = useRef<HTMLDivElement>(null);
```

**No Redux/Zustand needed** - React hooks sufficient for this use case.

---

## ğŸ¯ Key Design Decisions

1. **Why Projects instead of Tags?**
   - Stronger isolation
   - Clearer mental model
   - Better for team collaboration

2. **Why Map for Thinking Logs?**
   - O(1) lookup by message ID
   - Easy expansion/collapse tracking

3. **Why Set for Expanded State?**
   - Fast has() checks
   - Natural add/delete semantics

4. **Why Parallel Summary + Keywords?**
   - Cuts processing time in half
   - Both use same text chunk
   - Independent operations

5. **Why 200ms Rate Limit?**
   - Avoids Gemini API throttling
   - Barely noticeable to user
   - Prevents 429 errors

6. **Why 50 Chunk Limit?**
   - Balances coverage vs. speed
   - ~10 seconds total (acceptable)
   - Covers ~50,000 chars (plenty for most docs)

---

This architecture is **production-ready**, **scalable**, and **maintainable**! ğŸš€
